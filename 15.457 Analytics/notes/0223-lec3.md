# How to model and estimate f?
select a functional form or non paramemtric
theory-driven or data driven? maimtain the humanity when modelling

# Estimators
Frequent approach; Bayesian approach

theta: parameter vector
thai: a function of the model parameters
delta(x): an estimator of thai

random sample: n observations are drawn independently from the same population, iid

## example: estimating the sharpe ratio
sample from: R = mu + sigma * epsilon ~ N(mu, sigma^2)
estimate sharpe ratio mu / sigma
Intuition: sample mean amd sample standard error

another estimator: delta(x) = 0.2!

estimator is itself an RV: since it is a function of sample(RVs)
realizationi of estimator: estimate, or point estimate

## what makes a good estimator?
closeness, loss function
point estimates + further information (standard error)

### Consistency
as sample size increase to infinity, the estimator [converge in probability] to true value
### Unbiasedness
the conditional expectation of estimator equals true value

generally prefer consistency over unbiaseness since bias may be impossible to avoid

Unbiased but inconsistent: a single data point to estimate mean
consistent but biased: 

## Methods of Moments Estimator(MM)
estimate N dimensional parameter vector
consider a vector of N functions(moments) f_j(x, theta)

1. if theta = theta0, all Moments function expectation = 0 
2. if theta != theta0 at least one moment function is non zero

estimator theta_head = 

consistent but may biased
## Maximum Likelihood Estimator
probablity of observed data given the model parameters
multiple data: joint distribution, probability multiplied

pick parameter vector theta by maximizing p

MLE is consistent but also may be biased
## Bayesian Inference
1. likelihood function: p(x|theta) (possibility of observation given paramter)
2. prior distribution: p(theta) (possible parameter values)

Posterior: p(theta|x) = p(theta) * p(x|theta) / p(x)
p(x) = integrate p(x|theta)*p(theta) d(theta)

focus on numerator, denominator is like a "normalize" thing

reasonable range: sharpe ratio cannot exceed 10, finance theory come in?

### Predictive Distribution
forcast $E[X_{T+1}|X_1,...,X_T]$
past -> p(theta|x) ->p(x_{t+1}|theta)
p25: important derivation

essentially the forecast conditional on past data using models in between
p(xT+1|x) = integral p(xT+1|theta) p(theta|x) dtheta

### Example
prior on mu: p(mu): a normal distribution with two hyper parameters m0 and v0
likelihood: p(x|mu): multiple of every P(R_1|mu), function of mu

updated mean and v